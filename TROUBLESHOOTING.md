# ðŸ”§ Troubleshooting - N8N Autoscaler

Guia para resoluÃ§Ã£o dos problemas mais comuns do autoscaler.

## ðŸ”§ Problemas Comuns e SoluÃ§Ãµes

### 1. Problemas com Traefik e ResoluÃ§Ã£o de Nomes

**Erro:** `Failed to resolve 'docker-api-proxy'` ou `Name does not resolve`

**Causa:** Conflito entre Traefik e acesso direto ao Docker socket, ou serviÃ§os nÃ£o encontrados na rede.

**SoluÃ§Ãµes:**

#### OpÃ§Ã£o 1: Usar Stack EspecÃ­fica para Traefik
```bash
# Use a stack otimizada para Traefik
docker stack deploy -c stack-n8n-integration-traefik.yaml autoscaler-n8n

# Verificar se todos os serviÃ§os estÃ£o rodando
docker service ls | grep autoscaler-n8n
```

#### OpÃ§Ã£o 2: Verificar Conectividade de Rede
```bash
# Verificar se a rede CSNet existe e estÃ¡ ativa
docker network ls | grep CSNet

# Verificar serviÃ§os na rede
docker network inspect CSNet

# Testar conectividade entre serviÃ§os
docker exec -it $(docker ps -q -f name=autoscaler) ping docker-socket-proxy
```

#### OpÃ§Ã£o 3: Recriar a Rede CSNet
```bash
# Remover stack temporariamente
docker stack rm autoscaler-n8n

# Recriar a rede
docker network rm CSNet
docker network create --driver overlay --attachable CSNet

# Redeploy da stack
docker stack deploy -c stack-n8n-integration-traefik.yaml autoscaler-n8n
```

## ðŸš¨ Erro: Permission denied no Docker Socket

### Sintoma
```
ERROR - CRÃTICO: Falha ao conectar ao Redis ou Docker: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))
```

### Causa
O container do autoscaler nÃ£o tem permissÃµes para acessar o Docker socket (`/var/run/docker.sock`).

### SoluÃ§Ãµes

#### SoluÃ§Ã£o 1: Verificar Montagem do Volume (Mais Comum)

```bash
# Verificar se o volume estÃ¡ montado corretamente
docker service inspect autoscaler-n8n_autoscaler --format '{{.Spec.TaskTemplate.ContainerSpec.Mounts}}'

# Deve mostrar algo como:
# [{bind  /var/run/docker.sock /var/run/docker.sock   true rprivate}]
```

Se nÃ£o aparecer a montagem:

```bash
# Atualizar o serviÃ§o com a montagem correta
docker service update --mount-add type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock,readonly autoscaler-n8n_autoscaler
```

#### SoluÃ§Ã£o 2: Verificar PermissÃµes do Docker Socket

```bash
# Verificar permissÃµes do socket
ls -la /var/run/docker.sock

# Deve mostrar algo como:
# srw-rw---- 1 root docker 0 Jan 1 12:00 /var/run/docker.sock
```

Se as permissÃµes estiverem incorretas:

```bash
# Corrigir permissÃµes (cuidado em produÃ§Ã£o)
sudo chmod 666 /var/run/docker.sock

# Ou adicionar usuÃ¡rio ao grupo docker
sudo usermod -aG docker $USER
```

#### SoluÃ§Ã£o 3: Recriar o ServiÃ§o

```bash
# Remover stack atual
docker stack rm autoscaler-n8n

# Aguardar remoÃ§Ã£o completa
docker service ls | grep autoscaler

# Fazer deploy novamente
docker stack deploy -c stack-n8n-integration.yaml autoscaler-n8n
```

#### SoluÃ§Ã£o 4: Verificar Constraints de Placement

O serviÃ§o deve rodar apenas em nodes manager:

```bash
# Verificar nodes disponÃ­veis
docker node ls

# Verificar se o constraint estÃ¡ correto
docker service inspect autoscaler-n8n_autoscaler --format '{{.Spec.TaskTemplate.Placement.Constraints}}'

# Deve mostrar: [node.role == manager]
```

#### SoluÃ§Ã£o 5: Usar Docker Socket Proxy (Recomendado para ProduÃ§Ã£o)

Para maior seguranÃ§a, use um proxy do Docker socket:

```yaml
# Adicionar ao stack-n8n-integration.yaml
  docker-socket-proxy:
    image: tecnativa/docker-socket-proxy:latest
    networks:
      - CSNet
    environment:
      - CONTAINERS=1
      - SERVICES=1
      - SWARM=1
      - NODES=1
      - NETWORKS=1
      - TASKS=1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
```

E atualizar o autoscaler para usar o proxy:

```yaml
  autoscaler:
    # ... outras configuraÃ§Ãµes
    environment:
      # ... outras variÃ¡veis
      - DOCKER_HOST=tcp://docker-socket-proxy:2375
    # Remover volumes do docker.sock
    # volumes:
    #   - /var/run/docker.sock:/var/run/docker.sock:ro
```

## ðŸ” Erro: NÃ£o consegue conectar ao Redis

### Sintoma
```
ERROR - Falha ao conectar ao Redis: ConnectionError
```

### SoluÃ§Ãµes

#### Verificar Conectividade

```bash
# Testar conectividade do container
docker exec -it $(docker ps -q -f name=autoscaler) ping redis

# Testar conexÃ£o Redis
docker exec -it $(docker ps -q -f name=autoscaler) nc -zv redis 6379
```

#### Verificar ConfiguraÃ§Ãµes de Rede

```bash
# Verificar se ambos estÃ£o na mesma rede
docker service inspect redis --format '{{.Spec.TaskTemplate.Networks}}'
docker service inspect autoscaler-n8n_autoscaler --format '{{.Spec.TaskTemplate.Networks}}'
```

#### Verificar VariÃ¡veis de Ambiente

```bash
# Verificar configuraÃ§Ãµes do Redis
docker service inspect autoscaler-n8n_autoscaler --format '{{.Spec.TaskTemplate.ContainerSpec.Env}}'
```

## âš™ï¸ Erro: Worker N8N nÃ£o escala

### Sintoma
Filas cheias mas workers nÃ£o aumentam.

### SoluÃ§Ãµes

#### Verificar Nome do ServiÃ§o

```bash
# Listar serviÃ§os N8N
docker service ls | grep n8n

# Verificar nome configurado
docker service inspect autoscaler-n8n_autoscaler --format '{{.Spec.TaskTemplate.ContainerSpec.Env}}' | grep N8N_WORKER

# Atualizar se necessÃ¡rio
docker service update --env-add N8N_WORKER_SERVICE_NAME=nome_correto autoscaler-n8n_autoscaler
```

#### Verificar Thresholds

```bash
# Ver configuraÃ§Ãµes atuais
docker service logs autoscaler-n8n_autoscaler | grep -i threshold

# Ajustar se necessÃ¡rio
docker service update --env-add SCALE_UP_QUEUE_THRESHOLD=10 autoscaler-n8n_autoscaler
```

#### Verificar Cooldown

```bash
# Verificar se estÃ¡ em perÃ­odo de cooldown
docker service logs autoscaler-n8n_autoscaler | grep -i cooldown

# Reduzir cooldown se necessÃ¡rio
docker service update --env-add COOLDOWN_PERIOD_SECONDS=120 autoscaler-n8n_autoscaler
```

## ðŸ“Š Comandos de DiagnÃ³stico

### Verificar Status Geral

```bash
# Status de todos os serviÃ§os
docker service ls

# Status especÃ­fico do autoscaler
docker service ps autoscaler-n8n_autoscaler

# Logs em tempo real
docker service logs -f autoscaler-n8n_autoscaler
```

### Verificar Filas Redis

```bash
# Conectar ao Redis
docker exec -it $(docker ps -q -f name=redis) redis-cli

# Selecionar database correto
SELECT 2

# Verificar filas
KEYS bull:*
LLEN bull:jobs:waiting
LLEN bull:jobs:active
LLEN bull:jobs:completed
LLEN bull:jobs:failed
```

### Verificar Recursos

```bash
# Uso de recursos dos containers
docker stats --no-stream

# Recursos disponÃ­veis no Swarm
docker node ls
docker node inspect $(docker node ls -q) --format '{{.Description.Resources}}'
```

## ðŸ”„ ReinicializaÃ§Ã£o Completa

Se nada funcionar, reinicializaÃ§Ã£o completa:

```bash
# 1. Remover stack
docker stack rm autoscaler-n8n

# 2. Aguardar remoÃ§Ã£o
watch docker service ls

# 3. Limpar volumes Ã³rfÃ£os (opcional)
docker volume prune -f

# 4. Verificar rede
docker network ls | grep CSNet

# 5. Recriar se necessÃ¡rio
docker network rm CSNet
docker network create --driver overlay --attachable CSNet

# 6. Deploy novamente
docker stack deploy -c stack-n8n-integration.yaml autoscaler-n8n

# 7. Verificar logs
docker service logs -f autoscaler-n8n_autoscaler
```

## ðŸ“ž Suporte

Se o problema persistir:

1. Colete os logs: `docker service logs autoscaler-n8n_autoscaler > logs.txt`
2. Colete informaÃ§Ãµes do ambiente: `docker info > docker-info.txt`
3. Colete configuraÃ§Ãµes: `docker service inspect autoscaler-n8n_autoscaler > service-config.json`
4. Entre em contato com o suporte da Cyborg Solutions